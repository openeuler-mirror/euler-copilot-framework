# EulerCopilot 智能助手部署指南

版本信息
当前版本：v0.9.4
更新日期：2025年2月19日

## 概述

EulerCopilot 是一款智能问答工具，使用 EulerCopilot 可以解决操作系统知识获取的便捷性，并且为OS领域模型赋能开发者及运维人员。作为获取操作系统知识，使能操作系统生产力工具 (如 A-Ops / A-Tune / x2openEuler / EulerMaker / EulerDevOps / StratoVirt / iSulad 等)，颠覆传统命令交付方式，由传统命令交付方式向自然语义进化，并结合智能体任务规划能力，降低开发、使用操作系统特性的门槛。

本指南提供基于自动化脚本的EulerCopilot智能助手系统部署说明，支持一键自动部署和手动分步部署两种方式。

### 组件介绍

| 组件                          | 端口            | 说明                  |
| ----------------------------- | --------------- | -------------------- |
| euler-copilot-framework       | 8002 (内部端口) | 智能体框架服务         |
| euler-copilot-web             | 8080            | 智能体前端界面        |
| euler-copilot-rag             | 9988 (内部端口) | 检索增强服务           |
| authhub-backend-service       | 11120 (内部端口) | 鉴权服务后端          |
| authhub-web-service           | 8000            | 鉴权服务前端          |
| mysql                         | 3306 (内部端口) | MySQL数据库           |
| redis                         | 6379 (内部端口) | Redis数据库           |
| minio                         | 9000 (内部端口) 9001(外部部端口) | minio数据库       |
| mongo                         | 27017 (内部端口)         | mongo数据库           |
| postgres                      | 5432 (内部端口) | 向量数据库             |
| secret_inject                 | 无              | 配置文件安全复制工具   |

### 软件要求
|     类型        |      版本要求                         |  说明                                |
|----------------| -------------------------------------|--------------------------------------|
| 操作系统    | openEuler 22.03 LTS 及以上版本         | 无                                   |
| K3s        | >= v1.30.2，带有 Traefik Ingress 工具   | K3s 提供轻量级的 Kubernetes 集群，易于部署和管理 |
| Helm       | >= v3.15.3                           | Helm 是一个 Kubernetes 的包管理工具，其目的是快速安装、升级、卸载 EulerCopilot 服务 |
| python     | >=3.9.9                              | python3.9.9 以上版本为模型的下载和安装提供运行环境 |
---
### 硬件要求

| 硬件资源      |  服务器（最小要求）          | 服务器（推荐）               |
|--------------|----------------------------|------------------------------|
| CPU          | 4 核心                     | 16 核心及以上                 |
| RAM          | 4 GB                       | 64 GB                        |
| 存储         | 32 GB                      | 64G                         |
| 大模型名称    | deepseek-llm-7b-chat      |  DeepSeek-R1-Llama-8B         |                          
| 显存 (GPU)   |  8 GB (NVIDIA RTX A4000, 1个) | 16 GB (NVIDIA A100, 2个)    |


**注意**：
1. 若无 GPU 或 NPU 资源，建议通过调用 OpenAI 接口的方式来实现功能。
2. 调用第三方 OpenAI 接口的方式不需要安装高版本的 python (>=3.9.9)
4. 如果k8s集群环境，则不需要单独安装k3s，要求version >= 1.28

---
### 网络要求：
  - 可访问 hub.oepkgs.net
  - 可访问 modelscope.cn
  - 开放端口：80/443/
---
### 部署视图

![部署图](./pictures/部署视图.png)

---
### 域名要求
为确保 EulerCopilot 的正确部署和使用，请准备以下两个服务的域名：authhub、eulercopilot。这些子域名需属于同一个主域名下，例如 `www.eulercopilot.local`,`authhub.eulercopilot.local `

您可以通过两种方式来完成这项准备工作：

- **预先申请域名**：为每个服务（AuthHub、Euler Copilot）分别注册上述格式的子域名。

- **本地配置**：如果是在开发或测试环境中，您可以直接在本地Windows主机文件中进行配置。打开位于 `C:\Windows\System32\drivers\etc\hosts` 的文件，并添加相应的条目以映射这些子域名到本地或特定的IP地址，例如：
```bash
172.0.0.1 authhub.eulercopilot.local
172.0.0.1 www.eulercopilot.local
```
## 快速开始
### 一键部署
#### 1. 获取部署脚本

- 从 EulerCopilot 的官方Git仓库 [euler-copilot-framework](https://gitee.com/openeuler/euler-copilot-framework) 下载最新的部署仓库
- 如果您正在使用 Kubernetes，则不需要安装 k3s 工具。

```bash
# 下载目录以 home 为例
cd /home
```
```bash
git clone https://gitee.com/openeuler/euler-copilot-framework.git -b feat/ds-func-call
```
```bash
cd euler-copilot-framework/deploy/scripts
```
```bash
# 为脚本文件添加可执行权限
chmod -R +x ./*
```
#### 2. 执行主部署脚本（需要root权限）
```bash
./deploy.sh
```
#### 3. 输入0进行一键自动部署
```bash
==============================
        主部署菜单
==============================
0) 一键自动部署
1) 手动分步部署
2) 卸载所有组件并清除数据
3) 退出程序
==============================
请输入选项编号（0-3）: 0
```
---
### 手动分步部署

#### 步骤1：环境检查
```bash
sudo ./deploy.sh
# 选择1 -> 1 进入手动分步部署
==============================
       手动分步部署菜单
==============================
1) 执行环境检查脚本
2) 安装k3s和helm
3) 安装Ollama
4) 部署Deepseek模型
5) 部署Embedding模型
6) 安装数据库
7) 安装AuthHub
8) 安装EulerCopilot
9) 返回主菜单
==============================
请输入选项编号（0-9）:
```
#### 步骤2：输入选项编号（0-9），逐步部署
---
**注意事项**
1. 全程都需要保持互联网连接
2. 首次模型下载可能耗时较长（约30-60分钟）
3. 在部署过程中，您需要输入 Authhub 域名和 EulerCopilot 域名, 不输入则使用默认域名`authhub.eulercopilot.local`, `www.eulercopilot.local`。
4. Authhub部署完成后需要通过浏览器访问 `http://authhub.eulercopilot.local` 来手动创建 EulerCopilot 应用，并从生成的凭证中获取 client_id 和 client_secret。随后，请将这两个值准确无误地输入到部署控制台对应的位置。这样确保了在部署 EulerCopilot 之前，已正确配置其所需的认证信息。

![部署图](./pictures/authhub登录界面.png)
**AuthHub 登录默认账号 `administrator`, 密码 `changeme`**
创建应用EulerCopilot
![部署图](./pictures/创建应用界面.png)
点击**创建应用**后，请按照以下示例填写相关信息：
- **应用名称**: EulerCopilot
- **应用主页 URL**: https://www.eulercopilot.local
- **应用回调地址（登录后）**: https://www.eulercopilot.local/api/auth/login
- 点击**创建**，即可完成应用创建流程，系统将自动生成一个 **Client ID** 和 **Client Secret**。请保存好这对凭据，稍后在 `deploy/chart/euler_copilot/values.yaml` 配置文件中需要添加它们。  
![部署图](./pictures/创建应用成功界面.png)
5. 生产环境建议配置HTTPS证书
### 卸载所有组件
```bash
sudo ./deploy.sh
# 选择2进行完全卸载
==============================
        主部署菜单
==============================
0) 一键自动部署
1) 手动分步部署
2) 卸载所有组件并清除数据
3) 退出程序
==============================
请输入选项编号（0-3）: 2
```
---

## 故障排查
- 查看组件日志：
```bash
kubectl logs <pod名称> -n euler-copilot
```
- 修改配置更新单个组件：
```bash
# 示例：更新euler-copilot
cd /home/euler-copilot-framework/deploy/chart/euler-copilot
# 修改yaml
vim values.yaml
# 更新EulerCopilot
helm upgrade euler-copilot -n euler-copilot .
```

## 验证安装

恭喜您，**EulerCopilot** 已成功部署！为了开始您的体验，请在浏览器中输入 `https://您的EulerCopilot域名` 链接访问 EulerCopilot 的网页界面：

首次访问时，您需要点击页面上的 **立即注册** 按钮来创建一个新的账号，并完成登录过程。

![Web登录界面](./pictures/WEB登录界面.png)
![Web 界面](./pictures/WEB界面.png)

## 构建专有领域智能问答

点击知识库，可登录本地知识库管理页面，详细信息请参考文档 [本地资产库构建指南](./本地资产库构建指南.md)
**知识库登录默认账号 `admin`, 密码 `123456`**

---
## 附录

### 大模型准备
#### GPU 环境

可直接使用部署的deepseek大模型参考以下方式进行部署

1. 下载模型文件：

   ```bash
   huggingface-cli download --resume-download Qwen/Qwen1.5-14B-Chat --local-dir Qwen1.5-14B-Chat
   ```

2. 创建终端 control

   ```bash
   screen -S control
   ```

   ```bash
   python3 -m fastchat.serve.controller
   ```

   - 按 Ctrl A+D 置于后台

3. 创建新终端 api

   ```bash
   screen -S api
   ```

   ```bash
   python3 -m fastchat.serve.openai_api_server --host 0.0.0.0 --port 30000  --api-keys sk-123456
   ```

   - 按 Ctrl A+D 置于后台
   - 如果当前环境的 Python 版本是 3.12 或者 3.9 可以创建 python3.10 的 conda 虚拟环境

   ```bash
   mkdir -p /root/py310
   ```

   ```bash
   conda create --prefix=/root/py310 python==3.10.14
   ```

   ```bash
   conda activate /root/py310
   ```

4. 创建新终端 worker

   ```bash
   screen -S worker
   ```

   ```bash
   screen -r worker
   ```

   安装 fastchat 和 vllm

   ```bash
   pip install fschat vllm
   ```

   安装依赖：

   ```bash
   pip install fschat[model_worker]
   ```

   ```bash
   python3 -m fastchat.serve.vllm_worker --model-path /root/models/Qwen1.5-14B-Chat/ --model-name qwen1.5 --num-gpus 8 --gpu-memory-utilization=0.7 --dtype=half
   ```

   - 按 Ctrl A+D 置于后台

5. 按照如下方式配置文件，并更新服务。

   ```bash
   vim deploy/chart/euler_copilot/values.yaml
   ```

   修改如下部分

   ```yaml
   llm:
     # 开源大模型，OpenAI兼容接口
     openai:
       url: "http://$(IP):30000"
       key: "sk-123456"
       model: qwen1.5
       max_tokens: 8192
   ```

#### NPU 环境

NPU 环境部署可参考链接 [MindIE安装指南](https://www.hiascend.com/document/detail/zh/mindie/10RC2/whatismindie/mindie_what_0001.html)

### FAQ

#### 1. 解决 Hugging Face 连接错误

如果遇到如下连接错误：

```text
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object>: Failed to establish a new connection: [Errno 101] Network is unreachable
```

尝试以下解决方案：

- 更新 `huggingface_hub` 包到最新版本。

  ```bash
  pip3 install -U huggingface_hub
  ```

- 如果网络问题依旧存在，可以尝试使用镜像站点作为端点。

  ```bash
  export HF_ENDPOINT=https://hf-mirror.com
  ```

#### 2. 在 RAG 容器中调用问答接口

进入对应的 RAG Pod 后，可以通过 `curl` 命令发送 POST 请求来获取问答结果。请确保在请求体中提供具体的问题文本。

```bash
curl -k -X POST "http://localhost:9988/kb/get_answer" \
     -H "Content-Type: application/json" \
     -d '{
           "question": "您的问题",
           "kb_sn": "default_test",
           "fetch_source": true
         }'
```

#### 3. 解决 `helm upgrade` 错误

当 Kubernetes 集群不可达时，您可能会遇到类似下面的错误信息：

```text
Error: UPGRADE FAILED: Kubernetes cluster unreachable
```

确保设置了正确的 KUBECONFIG 环境变量指向有效的配置文件。

```bash
echo "export KUBECONFIG=/etc/rancher/k3s/k3s.yaml" >> /root/.bashrc
source /root/.bashrc
```

#### 4. 查看 Pod 日志失败

如果您遇到查看 Pod 日志时权限被拒绝的问题，检查是否正确配置了代理设置，并将本机 IP 地址添加到 `no_proxy` 环境变量中。

```bash
cat /etc/systemd/system/k3s.service.env
```

编辑文件并确保包含：

```bash
no_proxy=XXX.XXX.XXX.XXX
```

#### 5. GPU环境中大模型流式回复问题

对于某些服务执行 curl 大模型时无法进行流式回复的情况，尝试修改请求中的 `"stream"` 参数为 `false`。此外，确认已安装兼容版本的 Pydantic 库。

```bash
pip install pydantic==1.10.13
```

#### 6. sglang 模型部署指南

按照以下步骤部署基于 sglang 的模型：

```bash
# 1. 激活名为 `myenv` 的 Conda 环境，该环境基于 Python 3.10 创建：
conda activate myenv

# 2. 安装 sglang 及其所有依赖项，指定版本为 0.3.0
pip install "sglang[all]==0.3.0"

# 3. 从特定索引安装 flashinfer，确保与您的 CUDA 和 PyTorch 版本兼容
pip install flashinfer -i https://flashinfer.ai/whl/cu121/torch2.4/

# 4. 使用 sglang 启动服务器，配置如下：
python -m sglang.launch_server \
    --served-model-name Qwen2.5-32B \
    --model-path Qwen2.5-32B-Instruct-AWQ \
    --host 0.0.0.0 \
    --port 8001 \
    --api-key "sk-12345" \
    --mem-fraction-static 0.5 \
    --tp 8
```

- 验证安装

  ```bash
  pip show sglang
  pip show flashinfer
  ```

**注意事项：**
- API Key：请确保 `--api-key` 参数中的 API 密钥是正确的
- 模型路径： 确保 `--model-path` 参数中的路径是正确的，并且模型文件存在于该路径下。
- CUDA 版本：确保你的系统上安装了 CUDA 12.1 和 PyTorch 2.4，因为 `flashinfer` 包依赖于这些特定版本。
- 线程池大小：根据你的GPU资源和预期负载调整线程池大小。如果你有 8 个 GPU，那么可以选择 --tp 8 来充分利用这些资源。

#### 7. 获取 Embedding

使用 curl 发送 POST 请求以获取 embedding 结果：

```bash
curl -k -X POST http://localhost:11434/v1/embeddings \
     -H "Content-Type: application/json" \
     -d {"input": "The food was delicious and the waiter...", "model": "bge-m3", "encoding_format": "float"}
```
#### 8. 生成证书

为了生成自签名证书，首先下载 [mkcert](https://github.com/FiloSottile/mkcert/releases)工具，然后运行以下命令：
```bash
mkcert -install
mkcert example.com 
```
最后，将生成的证书和私钥拷贝到 values.yaml 中, 并应用至 Kubernetes Secret。
```bash
vim /home/euler-copilot-framework_openeuler/deploy/chart_ssl/traefik-secret.yaml
```
```bash
kubectl apply -f traefik-secret.yaml
```

#### 9. 问题排查方法

1. **获取集群事件信息**

   为了更好地定位 Pod 失败的原因，请首先检查 Kubernetes 集群中的事件 (Events)。这可以提供有关 Pod 状态变化的上下文信息。

   ```bash
   kubectl get events -n euler-copilot
   ```

2. **验证镜像拉取状态**

   确认容器镜像是否成功拉取。如果镜像未能正确加载，可能是由于网络问题或镜像仓库配置错误。

   ```bash
   k3s crictl images
   ```

3. **审查 Pod 日志**

   检查相关 Pod 的日志，以寻找可能的错误信息或异常行为。这对于诊断应用程序级别的问题特别有用。

   ```bash
   kubectl logs rag-deploy-service-5b7887644c-sm58z -n euler-copilot
   ```

4. **评估资源可用性**

   确保 Kubernetes 集群有足够的资源（如 CPU、内存和存储）来支持 Pod 的运行。资源不足可能导致镜像拉取失败或其他性能问题，或使得 Pod 状态从 Running 变为 Pending 或 Completed。可查看磁盘空间并保证至少有 30% 的可用空间。这有助于维持 Pod 的稳定运行状态。参考该链接挂载空间较大的磁盘[How to move k3s data to another location](https://mrkandreev.name/snippets/how_to_move_k3s_data_to_another_location/)


   ```bash
   kubectl top nodes
   ```

5. **确认 k3s 版本兼容性**

   如果遇到镜像拉取失败且镜像大小为 0 的问题，请检查您的 k3s 版本是否符合最低要求（v1.30.2 或更高）。较低版本可能存在不兼容的问题。

   ```bash
   k3s -v
   ```

6. **检查配置**

   检查 `values.yaml` 文件中关于 OIDC 配置和域名配置是否填写正确，确保配置无误后更新服务。

   ```bash
   cat /home/euler-copilot-framework/deploy/chart/euler_copilot
   ```
   ```bash
   vim values.yaml | grep oidc
   ```
   ```bash
   helm upgrade euler-copilot -n euler-copilot .
   ```
